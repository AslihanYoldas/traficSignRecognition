{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d35baf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets,layers,models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPool2D,Dense,Flatten,Dropout\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52e8183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=r'C:\\Users\\HP\\Desktop\\Trafik_isaretler_dataset\\Train'\n",
    "test_dir=r'C:\\Users\\HP\\Desktop\\Trafik_isaretler_dataset\\Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3a0a171",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [ 'Speed limit (20km/h)',\n",
    "            'Speed limit (30km/h)', \n",
    "            'Speed limit (50km/h)', \n",
    "            'Speed limit (60km/h)', \n",
    "            'Speed limit (70km/h)', \n",
    "            'Speed limit (80km/h)', \n",
    "            'End of speed limit (80km/h)', \n",
    "            'Speed limit (100km/h)', \n",
    "            'Speed limit (120km/h)', \n",
    "            'No passing', \n",
    "            'No passing veh over 3.5 tons', \n",
    "            'Right-of-way at intersection', \n",
    "            'Priority road', \n",
    "            'Yield', \n",
    "            'Stop', \n",
    "            'No vehicles', \n",
    "            'Veh > 3.5 tons prohibited', \n",
    "            'No entry', \n",
    "            'General caution', \n",
    "            'Dangerous curve left', \n",
    "            'Dangerous curve right', \n",
    "            'Double curve', \n",
    "            'Bumpy road', \n",
    "            'Slippery road', \n",
    "            'Road narrows on the right', \n",
    "            'Road work', \n",
    "            'Traffic signals', \n",
    "            'Pedestrians', \n",
    "            'Children crossing', \n",
    "            'Bicycles crossing', \n",
    "            'Beware of ice/snow',\n",
    "            'Wild animals crossing', \n",
    "            'End speed + passing limits', \n",
    "            'Turn right ahead', \n",
    "            'Turn left ahead', \n",
    "            'Ahead only', \n",
    "            'Go straight or right', \n",
    "            'Go straight or left', \n",
    "            'Keep right', \n",
    "            'Keep left', \n",
    "            'Roundabout mandatory', \n",
    "            'End of no passing', \n",
    "            'End no passing veh > 3.5 tons' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efb8de0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen=ImageDataGenerator(rescale=1./255 ,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61401bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31369 images belonging to 43 classes.\n",
      "Found 7841 images belonging to 43 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(100,100),\n",
    "    color_mode='rgb',\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "validation_generator=train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(100,100),\n",
    "    color_mode='rgb',\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c85dd4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0,\n",
       " '1': 1,\n",
       " '10': 2,\n",
       " '11': 3,\n",
       " '12': 4,\n",
       " '13': 5,\n",
       " '14': 6,\n",
       " '15': 7,\n",
       " '16': 8,\n",
       " '17': 9,\n",
       " '18': 10,\n",
       " '19': 11,\n",
       " '2': 12,\n",
       " '20': 13,\n",
       " '21': 14,\n",
       " '22': 15,\n",
       " '23': 16,\n",
       " '24': 17,\n",
       " '25': 18,\n",
       " '26': 19,\n",
       " '27': 20,\n",
       " '28': 21,\n",
       " '29': 22,\n",
       " '3': 23,\n",
       " '30': 24,\n",
       " '31': 25,\n",
       " '32': 26,\n",
       " '33': 27,\n",
       " '34': 28,\n",
       " '35': 29,\n",
       " '36': 30,\n",
       " '37': 31,\n",
       " '38': 32,\n",
       " '39': 33,\n",
       " '4': 34,\n",
       " '40': 35,\n",
       " '41': 36,\n",
       " '42': 37,\n",
       " '5': 38,\n",
       " '6': 39,\n",
       " '7': 40,\n",
       " '8': 41,\n",
       " '9': 42}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d435930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12629 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator=ImageDataGenerator(rescale=.1/255).flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(100,100),\n",
    "    color_mode='rgb',\n",
    "    batch_size=1,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19713f0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape=(1, 100, 100, 3), min=0.001, max=0.075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.04509804, 0.05411765, 0.06784314],\n",
       "        [0.04509804, 0.05411765, 0.06784314],\n",
       "        [0.04549019, 0.05411765, 0.06745098],\n",
       "        ...,\n",
       "        [0.03137255, 0.03960784, 0.04941176],\n",
       "        [0.02470588, 0.03215686, 0.04117647],\n",
       "        [0.02470588, 0.03215686, 0.04117647]],\n",
       "\n",
       "       [[0.04509804, 0.05411765, 0.06784314],\n",
       "        [0.04509804, 0.05411765, 0.06784314],\n",
       "        [0.04549019, 0.05411765, 0.06745098],\n",
       "        ...,\n",
       "        [0.03137255, 0.03960784, 0.04941176],\n",
       "        [0.02470588, 0.03215686, 0.04117647],\n",
       "        [0.02470588, 0.03215686, 0.04117647]],\n",
       "\n",
       "       [[0.04627451, 0.05607843, 0.06980392],\n",
       "        [0.04627451, 0.05607843, 0.06980392],\n",
       "        [0.04549019, 0.05490196, 0.06941176],\n",
       "        ...,\n",
       "        [0.04666667, 0.0545098 , 0.06549019],\n",
       "        [0.04588235, 0.05333333, 0.06509804],\n",
       "        [0.04588235, 0.05333333, 0.06509804]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.04470588, 0.05294118, 0.06549019],\n",
       "        [0.04470588, 0.05294118, 0.06549019],\n",
       "        [0.04470588, 0.05294118, 0.06470588],\n",
       "        ...,\n",
       "        [0.04509804, 0.0545098 , 0.06588235],\n",
       "        [0.04352941, 0.05490196, 0.06666666],\n",
       "        [0.04352941, 0.05490196, 0.06666666]],\n",
       "\n",
       "       [[0.04392157, 0.05294118, 0.06588235],\n",
       "        [0.04392157, 0.05294118, 0.06588235],\n",
       "        [0.04313726, 0.05254902, 0.06470588],\n",
       "        ...,\n",
       "        [0.04549019, 0.0545098 , 0.06666666],\n",
       "        [0.04509804, 0.05490196, 0.06745098],\n",
       "        [0.04509804, 0.05490196, 0.06745098]],\n",
       "\n",
       "       [[0.04392157, 0.05294118, 0.06588235],\n",
       "        [0.04392157, 0.05294118, 0.06588235],\n",
       "        [0.04313726, 0.05254902, 0.06470588],\n",
       "        ...,\n",
       "        [0.04549019, 0.0545098 , 0.06666666],\n",
       "        [0.04509804, 0.05490196, 0.06745098],\n",
       "        [0.04509804, 0.05490196, 0.06745098]]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchX  = test_generator.next()\n",
    "print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))\n",
    "type(batchX[0])\n",
    "batchX.dtype\n",
    "batchX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4e9921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5,5), activation='relu',input_shape=(100,100,3)))\n",
    "model.add(Conv2D(32, kernel_size=(5,5), activation='relu'))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(43,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9aadbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4edcfef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1960/1960 [==============================] - 272s 138ms/step - loss: 1.8605 - accuracy: 0.4501 - val_loss: 0.8099 - val_accuracy: 0.8083\n",
      "Epoch 2/20\n",
      "1960/1960 [==============================] - 271s 138ms/step - loss: 1.0332 - accuracy: 0.6523 - val_loss: 0.5263 - val_accuracy: 0.8624\n",
      "Epoch 3/20\n",
      "1960/1960 [==============================] - 270s 138ms/step - loss: 0.8529 - accuracy: 0.7042 - val_loss: 0.4114 - val_accuracy: 0.8902\n",
      "Epoch 4/20\n",
      "1960/1960 [==============================] - 270s 138ms/step - loss: 0.7670 - accuracy: 0.7318 - val_loss: 0.3316 - val_accuracy: 0.9162\n",
      "Epoch 5/20\n",
      "1960/1960 [==============================] - 267s 136ms/step - loss: 0.6903 - accuracy: 0.7586 - val_loss: 0.3174 - val_accuracy: 0.9168\n",
      "Epoch 6/20\n",
      "1960/1960 [==============================] - 266s 136ms/step - loss: 0.6229 - accuracy: 0.7807 - val_loss: 0.2917 - val_accuracy: 0.9277\n",
      "Epoch 7/20\n",
      "1960/1960 [==============================] - 266s 136ms/step - loss: 0.6015 - accuracy: 0.7875 - val_loss: 0.2561 - val_accuracy: 0.9245\n",
      "Epoch 8/20\n",
      "1960/1960 [==============================] - 266s 136ms/step - loss: 0.5691 - accuracy: 0.8010 - val_loss: 0.2318 - val_accuracy: 0.9374\n",
      "Epoch 9/20\n",
      "1960/1960 [==============================] - 266s 136ms/step - loss: 0.5528 - accuracy: 0.8026 - val_loss: 0.2667 - val_accuracy: 0.9268\n",
      "Epoch 10/20\n",
      "1960/1960 [==============================] - 266s 136ms/step - loss: 0.5468 - accuracy: 0.8051 - val_loss: 0.2139 - val_accuracy: 0.9376\n",
      "Epoch 11/20\n",
      "1960/1960 [==============================] - 266s 136ms/step - loss: 0.5186 - accuracy: 0.8152 - val_loss: 0.2155 - val_accuracy: 0.9384\n",
      "Epoch 12/20\n",
      "1960/1960 [==============================] - 266s 136ms/step - loss: 0.4924 - accuracy: 0.8234 - val_loss: 0.2250 - val_accuracy: 0.9357\n",
      "Epoch 13/20\n",
      "1960/1960 [==============================] - 266s 136ms/step - loss: 0.4909 - accuracy: 0.8253 - val_loss: 0.2522 - val_accuracy: 0.9390\n",
      "Epoch 14/20\n",
      "1960/1960 [==============================] - 266s 136ms/step - loss: 0.4796 - accuracy: 0.8329 - val_loss: 0.1856 - val_accuracy: 0.9497\n",
      "Epoch 15/20\n",
      "1960/1960 [==============================] - 266s 136ms/step - loss: 0.4459 - accuracy: 0.8415 - val_loss: 0.2415 - val_accuracy: 0.9385\n",
      "Epoch 16/20\n",
      "1960/1960 [==============================] - 266s 136ms/step - loss: 0.4483 - accuracy: 0.8411 - val_loss: 0.1956 - val_accuracy: 0.9454\n",
      "Epoch 17/20\n",
      "1960/1960 [==============================] - 266s 136ms/step - loss: 0.4357 - accuracy: 0.8459 - val_loss: 0.3555 - val_accuracy: 0.9367\n",
      "Epoch 18/20\n",
      "1960/1960 [==============================] - 266s 136ms/step - loss: 0.4226 - accuracy: 0.8517 - val_loss: 0.2353 - val_accuracy: 0.9401\n",
      "Epoch 19/20\n",
      "1960/1960 [==============================] - 267s 136ms/step - loss: 0.4344 - accuracy: 0.8467 - val_loss: 0.2343 - val_accuracy: 0.9408\n",
      "Epoch 20/20\n",
      "1960/1960 [==============================] - 266s 136ms/step - loss: 0.4121 - accuracy: 0.8541 - val_loss: 0.2008 - val_accuracy: 0.9462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b25527e760>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
    "model.fit(train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "623f01fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490/490 [==============================] - 23s 46ms/step - loss: 0.2008 - accuracy: 0.9462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2008277028799057, 0.9461734890937805]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validation_generator,\n",
    "steps=STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a616eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"trafik_model_43class_100x100.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "057c4372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(0, '0'), (1, '1'), (2, '10'), (3, '11'), (4, '12'), (5, '13'), (6, '14'), (7, '15'), (8, '16'), (9, '17'), (10, '18'), (11, '19'), (12, '2'), (13, '20'), (14, '21'), (15, '22'), (16, '23'), (17, '24'), (18, '25'), (19, '26'), (20, '27'), (21, '28'), (22, '29'), (23, '3'), (24, '30'), (25, '31'), (26, '32'), (27, '33'), (28, '34'), (29, '35'), (30, '36'), (31, '37'), (32, '38'), (33, '39'), (34, '4'), (35, '40'), (36, '41'), (37, '42'), (38, '5'), (39, '6'), (40, '7'), (41, '8'), (42, '9')])\n"
     ]
    }
   ],
   "source": [
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "print(labels.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "978cf03a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tenserflow\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tenserflow\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tenserflow\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tenserflow\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tenserflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tenserflow\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 100, 100, 3), found shape=(None, 224, 224, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5880\\1408467093.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tenserflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tenserflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tenserflow\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tenserflow\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tenserflow\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tenserflow\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tenserflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tenserflow\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 100, 100, 3), found shape=(None, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "file_name=r\"C:\\Users\\HP\\.spyder-py3\\imgsign.png\"\n",
    "img=cv2.imread(file_name)\n",
    "img=tf.expand_dims(img,axis=0)\n",
    "pred=model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e06e26cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b113e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "yuklenen_model=models.load_model(\"trafik_model_yeni.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
